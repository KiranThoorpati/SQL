# SQL CTAS: Physical Data Marts for Better Performance

## Understanding the Performance Challenge

Imagine a restaurant with two serving styles:

**Virtual Data Mart (Views):**
- Customer orders food
- Chef cooks FROM SCRATCH each time
- Takes 30 minutes per order
- 100 customers = 3,000 minutes of waiting!

**Physical Data Mart (CTAS Tables):**
- Chef prepares food at night
- Keeps it ready in warming trays
- Customer gets food in 2 minutes
- 100 customers = 200 minutes total!

---

## The Data Warehouse Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DATA WAREHOUSE (Central Storage)         â”‚
â”‚  â€¢ All company data stored here                  â”‚
â”‚  â€¢ Very large tables                             â”‚
â”‚  â€¢ Complex structure                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DATA MARTS (Focused Subsets)             â”‚
â”‚  Option A: Views (Virtual) - Slow but fresh     â”‚
â”‚  Option B: Tables (Physical) - Fast but needs   â”‚
â”‚            refresh                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      REPORTING LAYER (Power BI, Dashboards)      â”‚
â”‚  â€¢ Users need FAST responses                     â”‚
â”‚  â€¢ Performance matters most here!                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Problem with Virtual Data Marts (Views)

### Scenario Setup

```sql
-- DATA WAREHOUSE: Large central tables
CREATE TABLE warehouse_sales (
    transaction_id INT,
    product_id INT,
    product_name VARCHAR(100),
    category VARCHAR(50),
    quantity INT,
    unit_price DECIMAL(10,2),
    sale_date DATE,
    store_id INT,
    store_name VARCHAR(100),
    customer_id INT,
    customer_name VARCHAR(100)
);

-- Insert lots of data (simulating large warehouse)
INSERT INTO warehouse_sales VALUES
(1, 101, 'Laptop', 'Electronics', 2, 50000, '2025-01-15', 1, 'Mumbai Store', 1001, 'Amit Kumar'),
(2, 102, 'Mouse', 'Electronics', 10, 500, '2025-01-15', 1, 'Mumbai Store', 1002, 'Priya Singh'),
(3, 103, 'Notebook', 'Stationery', 50, 40, '2025-01-16', 2, 'Delhi Store', 1003, 'Rohan Patel'),
(4, 104, 'Pen', 'Stationery', 100, 10, '2025-01-16', 2, 'Delhi Store', 1004, 'Diya Reddy'),
(5, 105, 'Monitor', 'Electronics', 3, 15000, '2025-01-17', 1, 'Mumbai Store', 1005, 'Arjun Sharma'),
(6, 106, 'Keyboard', 'Electronics', 5, 1500, '2025-01-17', 3, 'Bangalore Store', 1006, 'Sneha Iyer');
-- Imagine 1 MILLION more rows here...
```

---

### Virtual Data Mart Using VIEW

```sql
-- DATA MART: Virtual (using View)
CREATE VIEW sales_mart_view AS
SELECT 
    product_name,
    category,
    SUM(quantity) AS total_quantity,
    SUM(quantity * unit_price) AS total_revenue,
    COUNT(DISTINCT customer_id) AS unique_customers,
    AVG(unit_price) AS avg_price,
    MIN(sale_date) AS first_sale,
    MAX(sale_date) AS last_sale
FROM warehouse_sales
GROUP BY product_name, category;
```

**Query the view:**
```sql
SELECT * FROM sales_mart_view;
```

**Output:**
```
product_name | category    | total_quantity | total_revenue | unique_customers | avg_price | first_sale  | last_sale
-------------|-------------|----------------|---------------|------------------|-----------|-------------|------------
Laptop       | Electronics | 2              | 100000.00     | 1                | 50000.00  | 2025-01-15  | 2025-01-15
Mouse        | Electronics | 10             | 5000.00       | 1                | 500.00    | 2025-01-15  | 2025-01-15
Notebook     | Stationery  | 50             | 2000.00       | 1                | 40.00     | 2025-01-16  | 2025-01-16
Pen          | Stationery  | 100            | 1000.00       | 1                | 10.00     | 2025-01-16  | 2025-01-16
Monitor      | Electronics | 3              | 45000.00      | 1                | 15000.00  | 2025-01-17  | 2025-01-17
Keyboard     | Electronics | 5              | 7500.00       | 1                | 1500.00   | 2025-01-17  | 2025-01-17
```

â±ï¸ **Time taken:** With 1 million rows, this could take **5-10 seconds or more!**

---

### The Performance Problem

**What happens when 100 users open dashboards:**

```
User 1 opens dashboard â†’ View queries warehouse â†’ 10 seconds
User 2 opens dashboard â†’ View queries warehouse â†’ 10 seconds
User 3 opens dashboard â†’ View queries warehouse â†’ 10 seconds
...
User 100 opens dashboard â†’ View queries warehouse â†’ 10 seconds

Total time wasted: 100 Ã— 10 = 1,000 seconds (16+ minutes!)
```

**Each dashboard refresh:**
- Queries the view
- View queries the warehouse
- Complex aggregations run
- Joins execute
- Results calculated
- **SLOW! SLOW! SLOW!**

---

## Solution: Physical Data Mart Using CTAS

### Strategy: Pre-calculate at Night

**The Plan:**
1. At night (when no users are working): Run CTAS
2. Creates physical table with all calculations done
3. Takes 30 minutes (but who cares? It's nighttime!)
4. Next morning: Users get instant results!

---

### Create Physical Data Mart

```sql
-- Run this at NIGHT (e.g., 2:00 AM)
CREATE TABLE sales_mart_physical AS
SELECT 
    product_name,
    category,
    SUM(quantity) AS total_quantity,
    SUM(quantity * unit_price) AS total_revenue,
    COUNT(DISTINCT customer_id) AS unique_customers,
    AVG(unit_price) AS avg_price,
    MIN(sale_date) AS first_sale,
    MAX(sale_date) AS last_sale,
    CURRENT_TIMESTAMP AS last_refreshed
FROM warehouse_sales
GROUP BY product_name, category;
```

**What happened:**
- âœ… Complex query executed ONCE
- âœ… Results stored in physical table
- âœ… All calculations pre-done
- âœ… Table ready for fast access

---

### Query the Physical Table

```sql
SELECT * FROM sales_mart_physical;
```

**Output:**
```
product_name | category    | total_quantity | total_revenue | unique_customers | avg_price | first_sale  | last_sale   | last_refreshed
-------------|-------------|----------------|---------------|------------------|-----------|-------------|-------------|-------------------
Laptop       | Electronics | 2              | 100000.00     | 1                | 50000.00  | 2025-01-15  | 2025-01-15  | 2025-10-07 02:00:00
Mouse        | Electronics | 10             | 5000.00       | 1                | 500.00    | 2025-01-15  | 2025-01-15  | 2025-10-07 02:00:00
Notebook     | Stationery  | 50             | 2000.00       | 1                | 40.00     | 2025-01-16  | 2025-01-16  | 2025-10-07 02:00:00
Pen          | Stationery  | 100            | 1000.00       | 1                | 10.00     | 2025-01-16  | 2025-01-16  | 2025-10-07 02:00:00
Monitor      | Electronics | 3              | 45000.00      | 1                | 15000.00  | 2025-01-17  | 2025-01-17  | 2025-10-07 02:00:00
Keyboard     | Electronics | 5              | 7500.00       | 1                | 1500.00   | 2025-01-17  | 2025-01-17  | 2025-10-07 02:00:00
```

âš¡ **Time taken:** 0.1 seconds! **INSTANT!**

---

### Performance Comparison

**100 Users with Physical Table:**

```
User 1 opens dashboard â†’ Reads from table â†’ 0.1 seconds
User 2 opens dashboard â†’ Reads from table â†’ 0.1 seconds
User 3 opens dashboard â†’ Reads from table â†’ 0.1 seconds
...
User 100 opens dashboard â†’ Reads from table â†’ 0.1 seconds

Total time: 100 Ã— 0.1 = 10 seconds (vs 1,000 seconds with views!)
```

**100Ã— FASTER!** ğŸš€

---

## Real-World Example: School Analytics Dashboard

### Setup: Large School Database

```sql
-- DATA WAREHOUSE: Student records
CREATE TABLE warehouse_student_data (
    student_id INT,
    student_name VARCHAR(50),
    class VARCHAR(10),
    subject VARCHAR(30),
    test_date DATE,
    marks INT,
    teacher_name VARCHAR(50),
    attendance_percent DECIMAL(5,2)
);

-- Insert sample data (imagine 100,000 students Ã— 5 subjects = 500,000 rows)
INSERT INTO warehouse_student_data VALUES
(1, 'Aarav', 'Class 7', 'Math', '2025-09-15', 85, 'Mrs. Gupta', 95.5),
(1, 'Aarav', 'Class 7', 'Science', '2025-09-15', 90, 'Mr. Singh', 95.5),
(1, 'Aarav', 'Class 7', 'English', '2025-09-15', 82, 'Mrs. Patel', 95.5),
(2, 'Diya', 'Class 7', 'Math', '2025-09-15', 92, 'Mrs. Gupta', 98.0),
(2, 'Diya', 'Class 7', 'Science', '2025-09-15', 88, 'Mr. Singh', 98.0),
(2, 'Diya', 'Class 7', 'English', '2025-09-15', 95, 'Mrs. Patel', 98.0),
(3, 'Rohan', 'Class 8', 'Math', '2025-09-15', 78, 'Mr. Sharma', 88.0),
(3, 'Rohan', 'Class 8', 'Science', '2025-09-15', 82, 'Mrs. Reddy', 88.0),
(3, 'Rohan', 'Class 8', 'English', '2025-09-15', 80, 'Mr. Kumar', 88.0);
-- ... 499,991 more rows
```

---

### Problem: Principal's Dashboard is SLOW

```sql
-- Virtual data mart (VIEW) - SLOW!
CREATE VIEW principal_dashboard_view AS
SELECT 
    class,
    COUNT(DISTINCT student_id) AS total_students,
    AVG(marks) AS average_marks,
    AVG(attendance_percent) AS average_attendance,
    COUNT(DISTINCT subject) AS subjects_taught,
    CASE 
        WHEN AVG(marks) >= 85 THEN 'Excellent'
        WHEN AVG(marks) >= 70 THEN 'Good'
        ELSE 'Needs Attention'
    END AS class_performance
FROM warehouse_student_data
GROUP BY class;
```

**When principal opens dashboard:**
```sql
SELECT * FROM principal_dashboard_view;
```

â±ï¸ **Wait time:** 15 seconds (principal gets frustrated!)

---

### Solution: Pre-build Physical Data Mart

```sql
-- Run at 1:00 AM every night (automated script)
DROP TABLE IF EXISTS principal_dashboard_physical;

CREATE TABLE principal_dashboard_physical AS
SELECT 
    class,
    COUNT(DISTINCT student_id) AS total_students,
    AVG(marks) AS average_marks,
    AVG(attendance_percent) AS average_attendance,
    COUNT(DISTINCT subject) AS subjects_taught,
    CASE 
        WHEN AVG(marks) >= 85 THEN 'Excellent'
        WHEN AVG(marks) >= 70 THEN 'Good'
        ELSE 'Needs Attention'
    END AS class_performance,
    CURRENT_DATE AS report_date
FROM warehouse_student_data
GROUP BY class;
```

**Next morning, principal opens dashboard:**
```sql
SELECT * FROM principal_dashboard_physical;
```

**Output (INSTANT!):**
```
class    | total_students | average_marks | average_attendance | subjects_taught | class_performance | report_date
---------|----------------|---------------|--------------------|-----------------|--------------------|-------------
Class 7  | 2              | 88.67         | 96.75              | 3               | Excellent          | 2025-10-07
Class 8  | 1              | 80.00         | 88.00              | 3               | Good               | 2025-10-07
```

âš¡ **Wait time:** 0.2 seconds (principal is happy!)

---

## Hybrid Approach: Mix Views and Tables

**Recommended Strategy:**

### Start with ALL Views

```sql
-- Data Mart 1: Sales (simple, fast enough)
CREATE VIEW sales_mart AS
SELECT ... FROM warehouse_sales;

-- Data Mart 2: Inventory (simple, fast enough)
CREATE VIEW inventory_mart AS
SELECT ... FROM warehouse_inventory;

-- Data Mart 3: Analytics (complex, SLOW!)
CREATE VIEW analytics_mart AS
SELECT ... -- Complex joins and calculations
FROM warehouse_sales ws
JOIN warehouse_customers wc ON ...
JOIN warehouse_products wp ON ...
-- More complex logic...
```

---

### Convert SLOW Marts to Physical Tables

```sql
-- Analytics mart is TOO SLOW!
-- Convert to physical table using CTAS

DROP VIEW analytics_mart;  -- Remove the slow view

CREATE TABLE analytics_mart AS
SELECT ... -- Same complex query
FROM warehouse_sales ws
JOIN warehouse_customers wc ON ...
JOIN warehouse_products wp ON ...;

-- Schedule daily refresh at night
```

**Result:**
- âœ… Simple marts stay as views (fresh data)
- âœ… Complex marts become tables (fast performance)
- âœ… Best of both worlds!

---

## Daily Refresh Schedule

### Automated Nightly Refresh

```sql
-- This script runs every night at 2:00 AM

-- Step 1: Drop old table
DROP TABLE IF EXISTS sales_mart_physical;

-- Step 2: Recreate with fresh data
CREATE TABLE sales_mart_physical AS
SELECT 
    product_name,
    category,
    SUM(quantity * unit_price) AS total_revenue,
    COUNT(*) AS transaction_count,
    AVG(unit_price) AS avg_price
FROM warehouse_sales
WHERE sale_date >= DATEADD(day, -30, CURRENT_DATE)  -- Last 30 days
GROUP BY product_name, category;

-- Step 3: Log completion
INSERT INTO refresh_log VALUES
('sales_mart_physical', CURRENT_TIMESTAMP, 'Success');
```

---

## Performance Comparison Table

| Aspect | Virtual Mart (View) | Physical Mart (CTAS) |
|--------|--------------------|--------------------|
| **Query Speed** | Slow (5-60 seconds) | Fast (0.1-1 second) |
| **Data Freshness** | Real-time | Updated nightly |
| **Storage Space** | Minimal | More space needed |
| **Maintenance** | Easy (no refresh) | Needs scheduled refresh |
| **Best For** | Simple queries | Complex aggregations |
| **User Experience** | Frustrating waits | Instant results |

---

## When to Convert View to Physical Table

### âœ… Convert to Physical Table When:
- â±ï¸ View takes more than 5 seconds
- ğŸ‘¥ Many users access simultaneously
- ğŸ“Š Complex joins and aggregations
- ğŸ”„ Data updates only once daily
- ğŸ“ˆ Dashboard performance critical

### âŒ Keep as View When:
- âš¡ View is already fast
- ğŸ”„ Need real-time data
- ğŸ“ Simple queries
- ğŸ‘¤ Few users
- ğŸ’¾ Limited storage space

---

## Summary

**Physical Data Marts (CTAS) Strategy:**

```
Night Time (2:00 AM):
    Run CTAS â†’ Create physical tables â†’ Takes 30 minutes
    (Nobody cares, everyone is sleeping!)

Day Time (9:00 AM - 6:00 PM):
    Users query tables â†’ Get instant results â†’ 0.1 seconds
    (Everyone is happy!)
```

**Key Benefits:**
- ğŸš€ 100Ã— faster query performance
- ğŸ˜Š Better user experience
- ğŸ“Š Supports complex analytics
- ğŸ‘¥ Handles many concurrent users

**Trade-off:**
- ğŸ”„ Data refreshed daily (not real-time)
- ğŸ’¾ Uses more storage
- âš™ï¸ Needs automated refresh jobs

**Best Practice:**
1. Start with views (easy and flexible)
2. Monitor performance
3. Convert slow views to tables
4. Keep simple views as views
5. Schedule nightly refreshes

**Remember:** It's better to prepare food at night than make 100 customers wait 30 minutes each during lunch rush!
